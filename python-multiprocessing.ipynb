{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocessing in Python\n",
    "What do you do if you want to run a Python code in parallel and utilize all cores? There is a `threading` package in Python, but turns out for some reason (something related to GlobalInterpreterLock) it cannot utilize multiple cores (and even multiple CPUs, I suppose)\n",
    "\n",
    "Creating multiple processes instead of threads is the way to go here. Creating processes is more expensive than threads but once you created it, they are basically the same in terms of speed.\n",
    "\n",
    "In Python, `multiprocessing` package does that for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import time # For measuring speedup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I know two ways of spawning processes:\n",
    "## 1. Doing it manually\n",
    "In this case, you should\n",
    "1. Create as many processes as you need.\n",
    "2. assign a function to the processes.\n",
    "2. Run them explicitly.\n",
    "3. Wait for them to finish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see an example.\n",
    "\n",
    "We first define an expensive to compute function and some input values and constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorial(n):\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    res = 1\n",
    "    for i in range(1, n+1):\n",
    "        res += i\n",
    "    print(res)\n",
    "    return res\n",
    "\n",
    "NUM_PROCESSES = 10\n",
    "INPUTS = [10000000+i for i in range(NUM_PROCESSES)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run the function on the set of inputs, sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000005000001\n",
      "50000015000002\n",
      "50000025000004\n",
      "50000035000007\n",
      "50000045000011\n",
      "50000055000016\n",
      "50000065000022\n",
      "50000075000029\n",
      "50000085000037\n",
      "50000095000046\n",
      "elapsed time = 7.363128185272217\n"
     ]
    }
   ],
   "source": [
    "t_0 = time.time()\n",
    "\n",
    "for arg in INPUTS:\n",
    "    factorial(arg)\n",
    "\n",
    "print('elapsed time = {}'.format(time.time() - t_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the same by making a process for each input and run them in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000025000004\n",
      "50000015000002\n",
      "50000005000001\n",
      "50000045000011\n",
      "50000035000007\n",
      "50000085000037\n",
      "50000055000016\n",
      "50000095000046\n",
      "50000065000022\n",
      "50000075000029\n",
      "elapsed time = 5.464713096618652\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process\n",
    "    \n",
    "t_0 = time.time()\n",
    "process_list = []\n",
    "for arg in INPUTS:\n",
    "    # Steps 1 and 2\n",
    "    process = Process(target = factorial, \n",
    "                     args = (arg, ))\n",
    "    # Step 3\n",
    "    process.start()\n",
    "    process_list.append(process)\n",
    "    \n",
    "for process in process_list:\n",
    "    # Step 4\n",
    "    process.join()\n",
    "    \n",
    "print('elapsed time = {}'.format(time.time() - t_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Let it figure it out\n",
    "What if you couldn't split the whole task into a few almost perfectly same sized tasks, i.e. a set of tasks that each can be done in almost the same time as the others? In this case, you can use `Pool`. You just need to\n",
    "- Specify the number of processes you want to create (it is even possible to not specify that, but at the time of writing this mini-tutorial I don't know how many processes will be created in that case)\n",
    "- Use `map` function to distribute the work for running a function on all elements of a list over this pool of processes. It returns back the return values of those functions inside another list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try out the same example using process pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000015000002\n",
      "50000025000004\n",
      "50000035000007\n",
      "50000055000016\n",
      "50000065000022\n",
      "50000045000011\n",
      "50000005000001\n",
      "50000075000029\n",
      "50000085000037\n",
      "50000095000046\n",
      "elapsed time = 5.701684951782227\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "t_0 = time.time()\n",
    "\n",
    "pool = Pool(NUM_PROCESSES)\n",
    "results = pool.map(factorial, INPUTS)\n",
    "\n",
    "print('elapsed time = {}'.format(time.time() - t_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some useful functions and attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `mp.current_process()` returns the Process object corresponding to the current process. Two useful attribute of this class are `name` and `pid`.\n",
    "- `mp.cpu_count` is supposed to return the number of CPUs on the machine. However, it could be the number of cores available.\n",
    "- `daemon`: There are two types of processes: daemonic and non-daemonic. When a process exits, it attempts to terminate all of its daemonic processes while it attempts to join its non-daemonic processes right before exitting. Note that setting `process.daemon` should be done before starting the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_MainProcess(MainProcess, started)>\n",
      "MainProcess\n",
      "58219\n"
     ]
    }
   ],
   "source": [
    "print(mp.current_process())\n",
    "print(mp.current_process().name)\n",
    "print(mp.current_process().pid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
